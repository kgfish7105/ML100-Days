--------------------------HW_1-----------------------
--------------------------HW_03-----------------------
讀檔 (非CSV的資料)

--------------------------HW_04-----------------------
DataFrame中最常?的欄位資料類型有三種:
float64 ： 浮點數，可表示離散或連續變數
int64 ： 整數，可表示離散或連續變數
object ： 包含字串，用於表示類別型變數

--------------------------HW_05-----------------------
計算資料分散程度: Min、Max、Range、Quartiles、Var、Std
計算集中趨勢
--------------------------HW_06-----------------------
Outlier 及處理 (視情況以中位數, Min, Max 或平均數填補(有時會用 NA))
繪製散點圖 (scatter)、分布圖 (histogram) 或其他圖(boxplot)檢查是否有異常

--------------------------HW_07-----------------------
常用的數值取代：中位數與分位數 連續數值標準化
np.quantile、np.median

--------------------------HW_08-----------------------
分群 groupby
cut, value_counts
DataFrame應用
df.loc[cond, 'col_name']
sub_df = df[['col1','col2']]
plt.boxplot(column=plt_column, by = plt_by)
Z轉換: 亦即將觀察值與母體平均數之間的距離，以標準差為單位來計算 (標準化)
--------------------------HW_09-----------------------
plt.scatter 看兩變數的相關性
正相關
負相關
--------------------------HW_10-----------------------
plt.boxplot 看有沒有outlier
seaborn.heatmap(相關係數)
seaborn.pairplot(相關係數)
--------------------------HW_11-----------------------
了解變數分布狀態: Bar & KDE (density plot)
np.linspace
sort_values(by='col_name')['col_name']
seaborn.barplot
seaborn.distplot (分布圖): 集合了matplotlib的 hist()、核密度函數kdeplot的功能
--------------------------HW_12-----------------------
連續資料離散化
cut, qcut, value_counts

--------------------------HW_13-----------------------
seaborn.catplot

--------------------------HW_14-----------------------
subplot
warnings.filterwarnings
np.sort
cut, groupby

--------------------------HW_15-----------------------
rand, randint, uniform, randn, normal

seaborn.heatmap
seaborn.PairGrid
kdeplot
--------------------------HW_16-----------------------
Imputer
MinMaxScaler
Fit the model
LogisticRegression
--------------------------HW_17-----------------------
LinearRegression.fit(train_X, train_Y)
train_Y = 轉換後的label

--------------------------HW_18-----------------------
常見資料型態: float、int、object
型態分類: type、int(var)、series.astype(int)

--------------------------HW_19-----------------------
<房價預測>
cross_val_score: 交叉驗證

填補缺失值
填補平均值(Mean) : 數值型欄位，偏態不明顯
• 填補中位數(Median) : 數值型欄位，偏態很明顯
• 填補眾數(Mode) : 類別型欄位

補不可能出現的數值 : 類別型欄位，但不適合用眾數時(篇態不明顯)

標準化 / 最小最大化 使用上的差異
標準化 : 轉換不易受到極端值影響
最小最大化 : 轉換容易受到極端值影響
所以 去除離群值的特徵，比較適和 最小最大化

非樹狀模型:  如線性迴歸, 羅吉斯迴歸, 類神經...等，標準化 / 最小最大化後對預測會有影響
樹狀模型 : 如決策樹, 隨機森林, 梯度提升樹...等，標準化 / 最小最大化後對預測不會有影響

邏輯回歸（Logistic Regression）是延伸自線性回歸（Linear Regression）的一種變形。
「回歸」一般來說指的是輸出變量為連續值的方法，而「分類」的輸出變量是離散型（Discrete）的。
所以實際上，邏輯回歸是用於分類的方法，而不是回歸。

--------------------------HW_20-----------------------
處理離峰值方法:
1. 調整離峰值 df['col'].clip(0,2500)
2. 捨棄離峰值 (df['col']> 0) & (df['col']< 2500)

--------------------------HW_21-----------------------
去除偏態:
薪資分布中，高薪群的長尾分布造成平均值不具代表性
但是對數去偏後的新分布，平均值就比較具有代表性
方根去偏(sqrt)
分布去偏(coxbox) 
對數去偏(log1p)   

--------------------------HW_22-----------------------
基礎編碼 1 : 標籤編碼 ( Label Encoding ): 耗時小。準確普通(適用樹狀模型)      
基礎編碼 2 : 獨熱編碼 ( One Hot Encoding ): 耗時大，準確高一點(適用非樹狀模型)


                           