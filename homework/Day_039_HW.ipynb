{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請閱讀相關文獻，並回答下列問題\n",
    "\n",
    "[脊回歸 (Ridge Regression)](https://blog.csdn.net/daunxx/article/details/51578787)\n",
    "[Linear, Ridge, Lasso Regression 本質區別](https://www.zhihu.com/question/38121173)\n",
    "\n",
    "1. LASSO 回歸可以被用來作為 Feature selection 的工具，請了解 LASSO 模型為什麼可用來作 Feature selection\n",
    "2. 當自變數 (X) 存在高度共線性時，Ridge Regression 可以處理這樣的問題嗎?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ans1\n",
    "L1正則化將系數w的l1範數作為懲罰項加到損失函數上，由於正則項非零，這就迫使那些弱的特征所對應的系數變成0。  \n",
    "因此L1正則化往往會使學到的模型很稀疏（系數w經常為0），這個特性使得L1正則化成為一種很好的特征選擇方法。\n",
    "\n",
    "正則項的權重就會越大，優化參數的結果就會偏好更小的參數值(W)，甚至很多W會變成0  \n",
    "當α 很大時，影響最小的W (feature)就會被留下來，所以可以當作Feature selection  \n",
    "y = wTx，當W很大，模型曲線就變得很複雜，W變小，曲線平滑。  \n",
    "通過降低權重係數的辦法來降低過擬合  \n",
    "那麼在線性模型中，降低權重係數就意味著與之相關的特徵並不重要，實際上就是對特徵做了一定的篩選。  \n",
    "LASSO的方法可以將某些權重係數降為零，這意味著，只有不會讓模型變overfiting的權重係數的特徵才會出現在模型中。\n",
    "\n",
    "原文網址：https://kknews.cc/other/v69vno4.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ans2\n",
    "根據: https://blog.csdn.net/daunxx/article/details/51578787  \n",
    "當使用最小二乘法計算線性回歸模型參數的時候，如果數據集合矩陣（也叫做設計矩陣(design matrix)）X，\n",
    "存在多重共線性，那麼最小二乘法對輸入變量中的噪聲非常的敏感，\n",
    "其解會極為不穩定。為了解決這個問題，就有了這一節脊回歸（Ridge Regression ）。\n",
    "\n",
    "一般的線性回歸其模型是y= wTx，顯然，就是因為w在數值上非常的大，所以，如果輸入變量x有一個微小的變動，\n",
    "其反應在輸出結果上也會變得非常大，這就是對輸入變量總的噪聲非常敏感的原因。\n",
    "\n",
    "所謂脊回歸，就是對於一個線性模型，在原來的損失函數加入參數的l2範數的懲罰項\n",
    "往極端化想，如果α -> ∞，則W勢必要很->0，才能滿足最小化 Loss function\n",
    "所以α 很大，就會導致大部分W都必須很小(模型就會變簡單)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例\n",
    "參考: https://www.itread01.com/content/1541226637.html  \n",
    "L1正則化將系數w的l1範數作為懲罰項加到損失函數上，由於正則項非零，這就迫使那些弱的特征所對應的系數變成0。  \n",
    "因此L1正則化往往會使學到的模型很稀疏（系數w經常為0），這個特性使得L1正則化成為一種很好的特征選擇方法。\n",
    "\n",
    "Scikit-learn為線性回歸提供了Lasso，為分類提供了L1邏輯回歸。  \n",
    "下面的例子在波士頓房價數據上運行了Lasso，其中參數alpha是通過grid search進行優化的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model: \n",
      " -3.707 * X12 + 2.992 * X5 + -1.757 * X10 + -1.081 * X7 + -0.7 * X4 + 0.631 * X11 + 0.54 * X3 + -0.236 * X0 + 0.081 * X1 + -0.0 * X2 + -0.0 * X6 + 0.0 * X8 + -0.0 * X9\n",
      "[-0.23616802  0.08100299 -0.          0.54017417 -0.70027816  2.99189989\n",
      " -0.         -1.08067403  0.         -0.         -1.75682067  0.63108483\n",
      " -3.70696598]\n",
      "Lasso model: \n",
      " -1.484 * X12 + 0.478 * X5 + -0.0 * X0 + 0.0 * X1 + -0.0 * X2 + 0.0 * X3 + -0.0 * X4 + -0.0 * X6 + 0.0 * X7 + -0.0 * X8 + -0.0 * X9 + -0.0 * X10 + 0.0 * X11\n",
      "[-0.          0.         -0.          0.         -0.          0.47793742\n",
      " -0.          0.         -0.         -0.         -0.          0.\n",
      " -1.4842917 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "#A helper method for pretty-printing linear models\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst, key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)\n",
    "\n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "\n",
    "lasso = Lasso(alpha=.3)\n",
    "lasso.fit(X, Y)\n",
    "\n",
    "print(\"Lasso model: \\n\", pretty_print_linear(lasso.coef_, sort = True))\n",
    "print(lasso.coef_)\n",
    "\n",
    "lasso = Lasso(alpha=5)\n",
    "lasso.fit(X, Y)\n",
    "\n",
    "print(\"Lasso model: \\n\", pretty_print_linear(lasso.coef_, sort = True))\n",
    "print(lasso.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以看到當alpha調大，更多W變成0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
