{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 K-fold Cross-validation 來切分資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (10, 5)\n",
      "Shape of y:  (10,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.arange(50).reshape(10, 5) # 生成從 0 到 50 的 array，並 reshape 成 (10, 5) 的 matrix\n",
    "y = np.zeros(10) # 生成一個全零 arrary\n",
    "y[:5] = 1 # 將一半的值改為 1\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of y: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x0000000008B789A8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "kf = KFold(n_splits=5)\n",
    "kf.split(X)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  [2 3 4 5 6 7 8 9]\n",
      "index2:  [0 1]\n",
      "FOLD 1: \n",
      "X_test:  [[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "Y_test:  [1. 1.]\n",
      "------------------------------\n",
      "index:  [0 1 4 5 6 7 8 9]\n",
      "index2:  [2 3]\n",
      "FOLD 2: \n",
      "X_test:  [[10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "Y_test:  [1. 1.]\n",
      "------------------------------\n",
      "index:  [0 1 2 3 6 7 8 9]\n",
      "index2:  [4 5]\n",
      "FOLD 3: \n",
      "X_test:  [[20 21 22 23 24]\n",
      " [25 26 27 28 29]]\n",
      "Y_test:  [1. 0.]\n",
      "------------------------------\n",
      "index:  [0 1 2 3 4 5 8 9]\n",
      "index2:  [6 7]\n",
      "FOLD 4: \n",
      "X_test:  [[30 31 32 33 34]\n",
      " [35 36 37 38 39]]\n",
      "Y_test:  [0. 0.]\n",
      "------------------------------\n",
      "index:  [0 1 2 3 4 5 6 7]\n",
      "index2:  [8 9]\n",
      "FOLD 5: \n",
      "X_test:  [[40 41 42 43 44]\n",
      " [45 46 47 48 49]]\n",
      "Y_test:  [0. 0.]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    i +=1 \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"index: \", train_index)\n",
    "    print(\"index2: \", test_index)\n",
    "    print(\"FOLD {}: \".format(i))\n",
    "    print(\"X_test: \", X_test)\n",
    "    print(\"Y_test: \", y_test)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流程:\n",
    "- 先把資料切成 train data(3/4)、 test data(1/4)\n",
    "- 把train data 用Cross validation(避免使model依賴同一組train data，泛化) 分別套用在Grid search找最佳參數\n",
    "- 統計每一輪cross validation的參數，選擇出現最多次數的那組參數\n",
    "- 套用model在test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13)\n",
      "(45, 13)\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state = 30)\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  68 out of  75 | elapsed:    7.1s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    8.0s finished\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1: \n",
      "X_test:  (106, 13)\n",
      "Y_test:  (27, 13)\n",
      "accuracy_tmp:  0.9629629629629629\n",
      "Best Accuracy: -0.009434 using {'max_depth': 1, 'n_estimators': 50}\n",
      "------------------------------\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  75 | elapsed:    5.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    5.9s finished\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2: \n",
      "X_test:  (106, 13)\n",
      "Y_test:  (27, 13)\n",
      "accuracy_tmp:  0.9259259259259259\n",
      "Best Accuracy: -0.037736 using {'max_depth': 1, 'n_estimators': 100}\n",
      "------------------------------\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  75 | elapsed:    5.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    5.7s finished\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3: \n",
      "X_test:  (106, 13)\n",
      "Y_test:  (27, 13)\n",
      "accuracy_tmp:  1.0\n",
      "Best Accuracy: -0.056604 using {'max_depth': 1, 'n_estimators': 50}\n",
      "------------------------------\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  75 | elapsed:    7.7s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    8.6s finished\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4: \n",
      "X_test:  (107, 13)\n",
      "Y_test:  (26, 13)\n",
      "accuracy_tmp:  0.9230769230769231\n",
      "Best Accuracy: -0.028037 using {'max_depth': 1, 'n_estimators': 75}\n",
      "------------------------------\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  75 | elapsed:    5.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    5.7s finished\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 5: \n",
      "X_test:  (107, 13)\n",
      "Y_test:  (26, 13)\n",
      "accuracy_tmp:  1.0\n",
      "Best Accuracy: -0.018692 using {'max_depth': 1, 'n_estimators': 125}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "n_estimators = [50, 75, 100, 125, 150]\n",
    "max_depth = [1,2,3,4,5]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    i +=1 \n",
    "    X_train_tmp, X_test_tmp = x_train[train_index], x_train[test_index]\n",
    "    y_train_tmp, y_test_tmp = y_train[train_index], y_train[test_index]\n",
    "#     print(\"index: \", train_index)\n",
    "#     print(\"index2: \", test_index)\n",
    "    \n",
    "    clf = GradientBoostingClassifier()\n",
    "#     clf.fit(X_train_tmp, y_train_tmp)\n",
    "#     y_pred_tmp = clf.predict(X_test_tmp)\n",
    "#     accuracy_tmp = metrics.accuracy_score(y_test_tmp, y_pred_tmp)\n",
    "    \n",
    "    ## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1)\n",
    "    # 開始搜尋最佳參數\n",
    "    grid_result = grid_search.fit(X_train_tmp, y_train_tmp)\n",
    "    \n",
    "    # 使用最佳參數重新建立模型\n",
    "    clf_bestparam = GradientBoostingClassifier(max_depth=grid_result.best_params_['max_depth'],\n",
    "                                               n_estimators=grid_result.best_params_['n_estimators'])\n",
    "\n",
    "    # 訓練模型\n",
    "    clf_bestparam.fit(X_train_tmp, y_train_tmp)\n",
    "\n",
    "    # 預測測試集\n",
    "    y_pred_tmp = clf_bestparam.predict(X_test_tmp)\n",
    "    \n",
    "    print(\"FOLD {}: \".format(i))\n",
    "    print(\"X_test: \", X_train_tmp.shape)\n",
    "    print(\"Y_test: \", X_test_tmp.shape)\n",
    "    print(\"accuracy_tmp: \", metrics.accuracy_score(y_test_tmp, y_pred_tmp))\n",
    "    print(\"Best Accuracy: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 由每一輪的Cross Validation可以得知\n",
    "- 共有2次 grid_search 得到參數:{max_depth:1 , n_estimators: 50} \n",
    "- 只有1次 grid_search 得到參數:{max_depth:1 , n_estimators: 75}\n",
    "- 只有1次 grid_search 得到參數:{max_depth:1 , n_estimators: 100}\n",
    "- 只有1次 grid_search 得到參數:{max_depth:1 , n_estimators: 125}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13)\n",
      "(45, 13)\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state = 30)\n",
    "clf = GradientBoostingClassifier(max_depth=1, n_estimators=50)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用參數: {max_depth:1 , n_estimators: 50} 得到最高的accuracy: 0.9777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隨機搜索參數調整\n",
    "- 隨機從給定區間中選擇參數是很有效的方法，然後根據這些參數來評估算法的效果進而選擇最佳的那個\n",
    "- https://www.jishuwen.com/d/2vQJ/zh-tw\n",
    "- https://stackoverflow.com/questions/40005795/how-does-sp-randint-work\n",
    "- https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html\n",
    "-  \n",
    "- Random Search (sp_rand)  \n",
    "-https://www.cnblogs.com/massquantity/p/10289285.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13)\n",
      "(45, 13)\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_rand\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state = 30)\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import uniform\n",
    "from scipy.stats import randint as sp_rand\n",
    "import numpy\n",
    "\n",
    "# sp_rand()\n",
    "# np.floor(1.5)\n",
    "randint(1, 100)\n",
    "# uniform(0,3)\n",
    "sp_rand(1,5)\n",
    "numpy.random.randint(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False),\n",
      "          fit_params=None, iid='warn', n_iter=100, n_jobs=None,\n",
      "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9EB8>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9B38>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "FOLD 1: \n",
      "X_test:  (106, 13)\n",
      "Y_test:  (27, 13)\n",
      "accuracy_tmp:  0.9629629629629629\n",
      "Best Accuracy: 0.990566 using {'max_depth': 1, 'n_estimators': 70}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False),\n",
      "          fit_params=None, iid='warn', n_iter=100, n_jobs=None,\n",
      "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9EB8>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9B38>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "FOLD 2: \n",
      "X_test:  (106, 13)\n",
      "Y_test:  (27, 13)\n",
      "accuracy_tmp:  0.9259259259259259\n",
      "Best Accuracy: 0.971698 using {'max_depth': 2, 'n_estimators': 86}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False),\n",
      "          fit_params=None, iid='warn', n_iter=100, n_jobs=None,\n",
      "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9EB8>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9B38>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "FOLD 3: \n",
      "X_test:  (106, 13)\n",
      "Y_test:  (27, 13)\n",
      "accuracy_tmp:  1.0\n",
      "Best Accuracy: 0.943396 using {'max_depth': 1, 'n_estimators': 50}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False),\n",
      "          fit_params=None, iid='warn', n_iter=100, n_jobs=None,\n",
      "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9EB8>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9B38>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "FOLD 4: \n",
      "X_test:  (107, 13)\n",
      "Y_test:  (26, 13)\n",
      "accuracy_tmp:  0.9230769230769231\n",
      "Best Accuracy: 0.971963 using {'max_depth': 1, 'n_estimators': 86}\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\RyderWu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False),\n",
      "          fit_params=None, iid='warn', n_iter=100, n_jobs=None,\n",
      "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9EB8>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000000093D9B38>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "FOLD 5: \n",
      "X_test:  (107, 13)\n",
      "Y_test:  (26, 13)\n",
      "accuracy_tmp:  1.0\n",
      "Best Accuracy: 0.962617 using {'max_depth': 1, 'n_estimators': 74}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from scipy.stats import randint as sp_rand\n",
    " \n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "# n_estimators = [50, 75, 100, 125, 150]\n",
    "# max_depth = [1,2,3,4,5]\n",
    "param_grid = dict(n_estimators=sp_rand(1,100), max_depth= sp_rand(1,10))\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    i +=1 \n",
    "    X_train_tmp, X_test_tmp = x_train[train_index], x_train[test_index]\n",
    "    y_train_tmp, y_test_tmp = y_train[train_index], y_train[test_index]\n",
    "#     print(\"index: \", train_index)\n",
    "#     print(\"index2: \", test_index)\n",
    "    \n",
    "    clf = GradientBoostingClassifier()\n",
    "#     clf.fit(X_train_tmp, y_train_tmp)\n",
    "#     y_pred_tmp = clf.predict(X_test_tmp)\n",
    "#     accuracy_tmp = metrics.accuracy_score(y_test_tmp, y_pred_tmp)\n",
    "    \n",
    "    ## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\n",
    "#     grid_search = GridSearchCV(clf, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1)\n",
    "\n",
    "    rand_search = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, n_iter=100)\n",
    "\n",
    "\n",
    "    # 開始搜尋最佳參數\n",
    "    rand_result = rand_search.fit(X_train_tmp, y_train_tmp)\n",
    "    print(rand_search)\n",
    "\n",
    "    \n",
    "    # 使用最佳參數重新建立模型\n",
    "    clf_bestparam = GradientBoostingClassifier(max_depth=rand_result.best_params_['max_depth'],\n",
    "                                               n_estimators=rand_result.best_params_['n_estimators'])\n",
    "\n",
    "    # 訓練模型\n",
    "    clf_bestparam.fit(X_train_tmp, y_train_tmp)\n",
    "\n",
    "    # 預測測試集\n",
    "    y_pred_tmp = clf_bestparam.predict(X_test_tmp)\n",
    "    \n",
    "    print(\"FOLD {}: \".format(i))\n",
    "    print(\"X_test: \", X_train_tmp.shape)\n",
    "    print(\"Y_test: \", X_test_tmp.shape)\n",
    "    print(\"accuracy_tmp: \", metrics.accuracy_score(y_test_tmp, y_pred_tmp))\n",
    "    print(\"Best Accuracy: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 由每一輪的Cross Validation可以得知\n",
    "- 第5次 random_search 參數:{max_depth:1 , n_estimators: 70} 最準，Best Accuracy = 0.9905 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13)\n",
      "(45, 13)\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state = 30)\n",
    "clf = GradientBoostingClassifier(max_depth=1, n_estimators=70)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
